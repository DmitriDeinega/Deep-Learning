{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30cb2791-423b-4a9b-98ee-6afb5d446bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99a8c480-f85c-4911-acbb-9f36a6aaa508",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2190f7da-1661-49b8-847c-83dfbfe9ce8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "inputs = torch.tensor([[2., 4.], [3., 9.], [4., 16.], [6., 36.], [7., 49.]])\n",
    "labels = torch.tensor([[70.], [110.], [165.], [390.], [550.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3577cb1f-2e09-41e8-97f4-ef76c0e4ee4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "89311.6015625\n",
      "w Grad tensor(-9881.1094, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-243.5826, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "200\n",
      "167.8958282470703\n",
      "w Grad tensor(0.3736, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-1.3273, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "400\n",
      "151.3308868408203\n",
      "w Grad tensor(0.5547, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-1.2511, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "600\n",
      "136.4982147216797\n",
      "w Grad tensor(0.5230, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-1.1839, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "800\n",
      "123.21639251708984\n",
      "w Grad tensor(0.4974, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-1.1202, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "1000\n",
      "111.32359313964844\n",
      "w Grad tensor(0.4712, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-1.0600, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "1200\n",
      "100.67411041259766\n",
      "w Grad tensor(0.4441, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-1.0031, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "1400\n",
      "91.13841247558594\n",
      "w Grad tensor(0.4213, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.9492, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "1600\n",
      "82.60000610351562\n",
      "w Grad tensor(0.4000, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.8982, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "1800\n",
      "74.95414733886719\n",
      "w Grad tensor(0.3768, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.8500, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "2000\n",
      "68.1080551147461\n",
      "w Grad tensor(0.3543, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.8043, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "2200\n",
      "61.97748565673828\n",
      "w Grad tensor(0.3342, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.7612, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "2400\n",
      "56.48821258544922\n",
      "w Grad tensor(0.3203, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.7202, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "2600\n",
      "51.57255172729492\n",
      "w Grad tensor(0.3027, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.6815, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "2800\n",
      "47.17116165161133\n",
      "w Grad tensor(0.2875, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.6449, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "3000\n",
      "43.230018615722656\n",
      "w Grad tensor(0.2709, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.6102, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "3200\n",
      "39.7009391784668\n",
      "w Grad tensor(0.2577, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.5774, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "3400\n",
      "36.54099655151367\n",
      "w Grad tensor(0.2440, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.5464, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "3600\n",
      "33.71150207519531\n",
      "w Grad tensor(0.2270, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.5171, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "3800\n",
      "31.177642822265625\n",
      "w Grad tensor(0.2169, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.4893, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "4000\n",
      "28.908954620361328\n",
      "w Grad tensor(0.2070, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.4630, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "4200\n",
      "26.877338409423828\n",
      "w Grad tensor(0.1915, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.4382, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "4400\n",
      "25.058225631713867\n",
      "w Grad tensor(0.1836, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.4146, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "4600\n",
      "23.429271697998047\n",
      "w Grad tensor(0.1752, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.3923, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "4800\n",
      "21.970813751220703\n",
      "w Grad tensor(0.1639, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.3713, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "5000\n",
      "20.664714813232422\n",
      "w Grad tensor(0.1549, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.3513, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "5200\n",
      "19.495290756225586\n",
      "w Grad tensor(0.1463, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.3324, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "5400\n",
      "18.448034286499023\n",
      "w Grad tensor(0.1362, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.3146, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "5600\n",
      "17.510419845581055\n",
      "w Grad tensor(0.1323, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.2977, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "5800\n",
      "16.67070770263672\n",
      "w Grad tensor(0.1261, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.2816, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "6000\n",
      "15.91887378692627\n",
      "w Grad tensor(0.1182, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.2665, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "6200\n",
      "15.24561595916748\n",
      "w Grad tensor(0.1128, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.2522, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "6400\n",
      "14.642829895019531\n",
      "w Grad tensor(0.1029, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.2387, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "6600\n",
      "14.103063583374023\n",
      "w Grad tensor(0.0974, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.2259, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "6800\n",
      "13.619732856750488\n",
      "w Grad tensor(0.0937, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.2137, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "7000\n",
      "13.186880111694336\n",
      "w Grad tensor(0.0897, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.2022, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "7200\n",
      "12.799314498901367\n",
      "w Grad tensor(0.0871, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.1913, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "7400\n",
      "12.452274322509766\n",
      "w Grad tensor(0.0801, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.1811, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "7600\n",
      "12.141561508178711\n",
      "w Grad tensor(0.0757, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.1714, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "7800\n",
      "11.863306999206543\n",
      "w Grad tensor(0.0702, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.1622, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "8000\n",
      "11.614137649536133\n",
      "w Grad tensor(0.0690, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.1534, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "8200\n",
      "11.391005516052246\n",
      "w Grad tensor(0.0668, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.1451, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "8400\n",
      "11.191303253173828\n",
      "w Grad tensor(0.0597, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.1374, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "8600\n",
      "11.012388229370117\n",
      "w Grad tensor(0.0578, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.1300, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "8800\n",
      "10.852222442626953\n",
      "w Grad tensor(0.0512, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.1231, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "9000\n",
      "10.70878791809082\n",
      "w Grad tensor(0.0518, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.1164, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "9200\n",
      "10.580343246459961\n",
      "w Grad tensor(0.0481, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.1102, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "9400\n",
      "10.465352058410645\n",
      "w Grad tensor(0.0452, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.1043, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "9600\n",
      "10.362373352050781\n",
      "w Grad tensor(0.0434, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.0986, grad_fn=<SumBackward0>)\n",
      "---------\n",
      "9800\n",
      "10.270146369934082\n",
      "w Grad tensor(0.0402, grad_fn=<SumBackward0>)\n",
      "b Grad tensor(-0.0934, grad_fn=<SumBackward0>)\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = LinearModel()\n",
    "\n",
    "# loss\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "for i in range(10000):\n",
    "    # Zero your gradients for every batch!\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # output of model\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    loss = loss_fn(outputs, labels)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 200 == 0:\n",
    "        print(i)\n",
    "        print(loss.item())\n",
    "        print('w Grad', torch.sum((inputs * (outputs - labels)) / 5))\n",
    "        print('b Grad', torch.sum((outputs - labels) / 5))\n",
    "        print('---------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "573be607-bd26-4a00-b384-1011be854012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[68.2442]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict for 5\n",
    "model(torch.tensor([[5., 25.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76e693b8-57dc-4d8c-8611-ffdf792ccb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-43.7394,  15.4762]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([96.5074], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Print weights\n",
    "for param in model.parameters():\n",
    "  print(param)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
