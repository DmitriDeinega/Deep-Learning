{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c6b4389-f7c9-457f-b80f-c6f919da022a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91adedbe-f9ae-4cfc-a97b-ce7206dc50b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = nn.functional.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f55265fc-6fbb-428f-b9b3-4c5a8082b258",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 0\n",
    "word2location = {}\n",
    "\n",
    "def prepare_vocabulary(data):\n",
    "    idx = 0\n",
    "    for sentence in data:\n",
    "        for word in sentence.split():\n",
    "            if word not in word2location:\n",
    "                word2location[word] = idx\n",
    "                idx += 1\n",
    "    return idx\n",
    "\n",
    "def convert2vec(sentence):\n",
    "    res_vec = np.zeros(vocabulary_size)\n",
    "    for word in sentence.split():\n",
    "        if word in word2location:\n",
    "            res_vec[word2location[word]] += 1\n",
    "\n",
    "    return res_vec\n",
    "\n",
    "data = [\"Where are you? I'm trying to reach you for half an hour already, contact me ASAP I need to leave now!\",\n",
    "        \"I want to go out for lunch, let me know in the next couple of minutes if you would like to join.\",\n",
    "        \"I was wondering whether you are planning to attend the party we are having next month.\",\n",
    "        \"I wanted to share my thought with you.\"]\n",
    "\n",
    "vocabulary_size = prepare_vocabulary(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8329507-8321-4276-96c2-c4fa253c436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.FloatTensor([convert2vec(data[0]), convert2vec(data[1]), convert2vec(data[2]), convert2vec(data[3])])\n",
    "labels = torch.FloatTensor([[1], [1], [0], [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bdc4327-03bd-4c6f-9944-5f8dcfbb0bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.660953164100647\n",
      "---------\n",
      "200\n",
      "0.6592991352081299\n",
      "---------\n",
      "400\n",
      "0.6576524972915649\n",
      "---------\n",
      "600\n",
      "0.6560136675834656\n",
      "---------\n",
      "800\n",
      "0.6543826460838318\n",
      "---------\n",
      "1000\n",
      "0.6527591347694397\n",
      "---------\n",
      "1200\n",
      "0.6511423587799072\n",
      "---------\n",
      "1400\n",
      "0.6495336890220642\n",
      "---------\n",
      "1600\n",
      "0.6479319334030151\n",
      "---------\n",
      "1800\n",
      "0.646338164806366\n",
      "---------\n",
      "2000\n",
      "0.6447509527206421\n",
      "---------\n",
      "2200\n",
      "0.6431711912155151\n",
      "---------\n",
      "2400\n",
      "0.6415989995002747\n",
      "---------\n",
      "2600\n",
      "0.6400336623191833\n",
      "---------\n",
      "2800\n",
      "0.6384761333465576\n",
      "---------\n",
      "3000\n",
      "0.6369247436523438\n",
      "---------\n",
      "3200\n",
      "0.6353808641433716\n",
      "---------\n",
      "3400\n",
      "0.6338437795639038\n",
      "---------\n",
      "3600\n",
      "0.6323136687278748\n",
      "---------\n",
      "3800\n",
      "0.6307904720306396\n",
      "---------\n",
      "4000\n",
      "0.6292738914489746\n",
      "---------\n",
      "4200\n",
      "0.627764105796814\n",
      "---------\n",
      "4400\n",
      "0.6262615323066711\n",
      "---------\n",
      "4600\n",
      "0.6247653961181641\n",
      "---------\n",
      "4800\n",
      "0.623275637626648\n",
      "---------\n",
      "5000\n",
      "0.6217929124832153\n",
      "---------\n",
      "5200\n",
      "0.6203165650367737\n",
      "---------\n",
      "5400\n",
      "0.618847131729126\n",
      "---------\n",
      "5600\n",
      "0.6173836588859558\n",
      "---------\n",
      "5800\n",
      "0.6159263253211975\n",
      "---------\n",
      "6000\n",
      "0.6144759654998779\n",
      "---------\n",
      "6200\n",
      "0.6130316853523254\n",
      "---------\n",
      "6400\n",
      "0.6115942597389221\n",
      "---------\n",
      "6600\n",
      "0.6101627349853516\n",
      "---------\n",
      "6800\n",
      "0.6087368726730347\n",
      "---------\n",
      "7000\n",
      "0.6073178052902222\n",
      "---------\n",
      "7200\n",
      "0.6059046983718872\n",
      "---------\n",
      "7400\n",
      "0.6044982075691223\n",
      "---------\n",
      "7600\n",
      "0.6030973196029663\n",
      "---------\n",
      "7800\n",
      "0.6017021536827087\n",
      "---------\n",
      "8000\n",
      "0.6003129482269287\n",
      "---------\n",
      "8200\n",
      "0.5989304780960083\n",
      "---------\n",
      "8400\n",
      "0.5975539684295654\n",
      "---------\n",
      "8600\n",
      "0.5961830019950867\n",
      "---------\n",
      "8800\n",
      "0.5948180556297302\n",
      "---------\n",
      "9000\n",
      "0.5934586524963379\n",
      "---------\n",
      "9200\n",
      "0.5921050906181335\n",
      "---------\n",
      "9400\n",
      "0.5907577276229858\n",
      "---------\n",
      "9600\n",
      "0.589415431022644\n",
      "---------\n",
      "9800\n",
      "0.5880789160728455\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = LogisticModel(vocabulary_size)\n",
    "\n",
    "# loss\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = SGD(model.parameters(), lr=0.00001)\n",
    "\n",
    "for i in range(10000):\n",
    "    # Zero your gradients for every batch!\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # output of model\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    loss = loss_fn(outputs, labels)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 200 == 0:\n",
    "        print(i)\n",
    "        print(loss.item())\n",
    "        print('---------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4bcc7dac-71bd-4fda-ad8e-3a94710c25a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5339], grad_fn=<SigmoidBackward0>)\n",
      "tensor([0.4837], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model(torch.FloatTensor(convert2vec(\"I need you now! Please answer ASAP!\"))))\n",
    "print(model(torch.FloatTensor(convert2vec(\"I wanted to hear your thoughts about my plans.\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f62eb7f0-9870-43af-9aad-f698af816efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0470, -0.0672,  0.0568,  0.0685, -0.0417,  0.0971,  0.0850,  0.1281,\n",
      "         -0.0225, -0.0430, -0.0765, -0.0849,  0.0028,  0.1283, -0.0007, -0.0007,\n",
      "         -0.0517, -0.0241,  0.0273,  0.1143,  0.0379, -0.0968, -0.0995, -0.0844,\n",
      "          0.0095, -0.0046, -0.0313,  0.1256, -0.0683,  0.1363, -0.0686,  0.0506,\n",
      "          0.0714,  0.0023, -0.0800,  0.1329,  0.0266, -0.1091,  0.0265, -0.0387,\n",
      "          0.1082,  0.0157, -0.0351, -0.0139, -0.1442, -0.0043, -0.0636, -0.0760,\n",
      "         -0.0093,  0.0235, -0.0455]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0306], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "  print(param)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
