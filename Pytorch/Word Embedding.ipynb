{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cab5103-8e56-4a38-a57c-53c841ffcb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84558e0b-a417-4f37-91e9-4e0fd2aa79e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "royal = ['queen', 'king', 'prince', 'princess']\n",
    "plain = ['woman', 'man', 'girl', 'boy']\n",
    "peafowl = ['peacock', 'peahen', 'peachick']\n",
    "adult = ['queen', 'king', 'woman', 'man', 'peacock', 'peahen']\n",
    "female = ['queen', 'princess', 'woman', 'girl', 'peahen']\n",
    "male = ['king', 'prince', 'man', 'boy', 'peacock']\n",
    "young = ['prince', 'princess', 'girl', 'boy', 'peachick']\n",
    "\n",
    "union_data = [royal, plain, peafowl, adult, female, male, young]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7e62eb4-2339-45c6-a8e4-d86b4f9fc7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'queen': 0, 'king': 1, 'prince': 2, 'princess': 3, 'woman': 4, 'man': 5, 'girl': 6, 'boy': 7, 'peacock': 8, 'peahen': 9, 'peachick': 10}\n",
      "vocabulary_size 11\n"
     ]
    }
   ],
   "source": [
    "all_data = royal + plain + peafowl + adult + female + male + young\n",
    "vocabulary_size = 0\n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "for data in all_data:\n",
    "    if data not in data_dict:\n",
    "        data_dict[data] = vocabulary_size\n",
    "        vocabulary_size += 1\n",
    "\n",
    "one_hot = []\n",
    "\n",
    "for i in range(vocabulary_size):\n",
    "    arr = [0] * vocabulary_size\n",
    "    arr[i] = 1\n",
    "    one_hot.append(arr)\n",
    "\n",
    "print(data_dict)\n",
    "print('vocabulary_size', vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e05838cc-28a9-493b-ae2f-deb4fc0ebfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2, 0.13333333333333333, 0.06666666666666667, 0.13333333333333333, 0.13333333333333333, 0.06666666666666667, 0.06666666666666667, 0.0, 0.06666666666666667, 0.13333333333333333, 0.0], [0.13333333333333333, 0.2, 0.13333333333333333, 0.06666666666666667, 0.06666666666666667, 0.13333333333333333, 0.0, 0.06666666666666667, 0.13333333333333333, 0.06666666666666667, 0.0], [0.07142857142857142, 0.14285714285714285, 0.21428571428571427, 0.14285714285714285, 0.0, 0.07142857142857142, 0.07142857142857142, 0.14285714285714285, 0.07142857142857142, 0.0, 0.07142857142857142], [0.14285714285714285, 0.07142857142857142, 0.14285714285714285, 0.21428571428571427, 0.07142857142857142, 0.0, 0.14285714285714285, 0.07142857142857142, 0.0, 0.07142857142857142, 0.07142857142857142], [0.13333333333333333, 0.06666666666666667, 0.0, 0.06666666666666667, 0.2, 0.13333333333333333, 0.13333333333333333, 0.06666666666666667, 0.06666666666666667, 0.13333333333333333, 0.0], [0.06666666666666667, 0.13333333333333333, 0.06666666666666667, 0.0, 0.13333333333333333, 0.2, 0.06666666666666667, 0.13333333333333333, 0.13333333333333333, 0.06666666666666667, 0.0], [0.07142857142857142, 0.0, 0.07142857142857142, 0.14285714285714285, 0.14285714285714285, 0.07142857142857142, 0.21428571428571427, 0.14285714285714285, 0.0, 0.07142857142857142, 0.07142857142857142], [0.0, 0.07142857142857142, 0.14285714285714285, 0.07142857142857142, 0.07142857142857142, 0.14285714285714285, 0.14285714285714285, 0.21428571428571427, 0.07142857142857142, 0.0, 0.07142857142857142], [0.07142857142857142, 0.14285714285714285, 0.07142857142857142, 0.0, 0.07142857142857142, 0.14285714285714285, 0.0, 0.07142857142857142, 0.21428571428571427, 0.14285714285714285, 0.07142857142857142], [0.14285714285714285, 0.07142857142857142, 0.0, 0.07142857142857142, 0.14285714285714285, 0.07142857142857142, 0.07142857142857142, 0.0, 0.14285714285714285, 0.21428571428571427, 0.07142857142857142], [0.0, 0.0, 0.125, 0.125, 0.0, 0.0, 0.125, 0.125, 0.125, 0.125, 0.25]]\n"
     ]
    }
   ],
   "source": [
    "mat = []\n",
    "\n",
    "for i in range(vocabulary_size):\n",
    "    mat.append([0] * vocabulary_size)\n",
    "\n",
    "for data in union_data:\n",
    "    for value1 in data:\n",
    "        for value2 in data:\n",
    "            mat[data_dict[value1]][data_dict[value2]] += 1\n",
    "\n",
    "for arr in mat:\n",
    "    arr_sum = sum(arr)\n",
    "    for i in range(vocabulary_size):\n",
    "        arr[i] /= arr_sum\n",
    "\n",
    "print(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6fb701a4-34e7-42be-a7b1-27cc809a923d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Linear(11, 3)\n",
    "        self.decoder = nn.Linear(3, 11)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.decoder(x)\n",
    "        x = F.softmax(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93e39075-c71b-4eeb-8937-8f69f5ecdecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "143e036f-1ee2-47bd-b61a-7f1af7cefdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dima\\AppData\\Local\\Temp\\ipykernel_1796\\1100895134.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.005127913784235716\n",
      "---------\n",
      "200\n",
      "0.0037645548582077026\n",
      "---------\n",
      "400\n",
      "0.0029659634456038475\n",
      "---------\n",
      "600\n",
      "0.002141873352229595\n",
      "---------\n",
      "800\n",
      "0.0018871099455282092\n",
      "---------\n",
      "1000\n",
      "0.001799478312022984\n",
      "---------\n",
      "1200\n",
      "0.0017258874140679836\n",
      "---------\n",
      "1400\n",
      "0.0016243611462414265\n",
      "---------\n",
      "1600\n",
      "0.001532913651317358\n",
      "---------\n",
      "1800\n",
      "0.0014811857836320996\n",
      "---------\n",
      "2000\n",
      "0.0014450608287006617\n",
      "---------\n",
      "2200\n",
      "0.0014112046919763088\n",
      "---------\n",
      "2400\n",
      "0.0013770295772701502\n",
      "---------\n",
      "2600\n",
      "0.001336578861810267\n",
      "---------\n",
      "2800\n",
      "0.0012814679648727179\n",
      "---------\n",
      "3000\n",
      "0.001224022009409964\n",
      "---------\n",
      "3200\n",
      "0.0011929180473089218\n",
      "---------\n",
      "3400\n",
      "0.001180856255814433\n",
      "---------\n",
      "3600\n",
      "0.0011756578460335732\n",
      "---------\n",
      "3800\n",
      "0.0011729415273293853\n",
      "---------\n",
      "4000\n",
      "0.0011712646810337901\n",
      "---------\n",
      "4200\n",
      "0.0011700852774083614\n",
      "---------\n",
      "4400\n",
      "0.00116917013656348\n",
      "---------\n",
      "4600\n",
      "0.0011684098280966282\n",
      "---------\n",
      "4800\n",
      "0.0011677492875605822\n",
      "---------\n",
      "5000\n",
      "0.0011671605752781034\n",
      "---------\n",
      "5200\n",
      "0.001166630070656538\n",
      "---------\n",
      "5400\n",
      "0.0011661509051918983\n",
      "---------\n",
      "5600\n",
      "0.0011657198192551732\n",
      "---------\n",
      "5800\n",
      "0.0011653352994471788\n",
      "---------\n",
      "6000\n",
      "0.0011649958323687315\n",
      "---------\n",
      "6200\n",
      "0.0011646999046206474\n",
      "---------\n",
      "6400\n",
      "0.00116444518789649\n",
      "---------\n",
      "6600\n",
      "0.001164229353889823\n",
      "---------\n",
      "6800\n",
      "0.0011640491429716349\n",
      "---------\n",
      "7000\n",
      "0.001163901062682271\n",
      "---------\n",
      "7200\n",
      "0.001163781387731433\n",
      "---------\n",
      "7400\n",
      "0.0011636867420747876\n",
      "---------\n",
      "7600\n",
      "0.0011636136332526803\n",
      "---------\n",
      "7800\n",
      "0.0011635604314506054\n",
      "---------\n",
      "8000\n",
      "0.0011635251576080918\n",
      "---------\n",
      "8200\n",
      "0.001163498847745359\n",
      "---------\n",
      "8400\n",
      "0.0011634790571406484\n",
      "---------\n",
      "8600\n",
      "0.0011634640395641327\n",
      "---------\n",
      "8800\n",
      "0.0011634528636932373\n",
      "---------\n",
      "9000\n",
      "0.0011634448310360312\n",
      "---------\n",
      "9200\n",
      "0.0011634392431005836\n",
      "---------\n",
      "9400\n",
      "0.001163435517810285\n",
      "---------\n",
      "9600\n",
      "0.001163432956673205\n",
      "---------\n",
      "9800\n",
      "0.001163431559689343\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = WordEmbedding().to(device)\n",
    "\n",
    "# loss\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = Adam(model.parameters())\n",
    "\n",
    "inputs = torch.FloatTensor(one_hot).to(device)\n",
    "labels = torch.tensor(mat).to(device)\n",
    "\n",
    "for i in range(10000):\n",
    "    # Zero your gradients for every batch!\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    loss = loss_fn(outputs, labels)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 200 == 0:\n",
    "        print(i)\n",
    "        print(loss.item())\n",
    "        print('---------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e594c56-79bc-4d6c-aafc-156227ea62e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.478389024734497, -0.4531126618385315, 0.0028105974197387695],\n",
       " [2.2923765182495117, -0.3491453230381012, 1.3273496627807617],\n",
       " [0.9251213073730469, -0.18233001232147217, 1.5837090015411377],\n",
       " [0.0009860992431640625, -0.1157941222190857, 0.07974356412887573],\n",
       " [1.476144790649414, -0.25407806038856506, -0.16513627767562866],\n",
       " [2.2919044494628906, -0.09289124608039856, 1.325872540473938],\n",
       " [-2.4199485778808594e-05, -0.5068918466567993, 0.07789519429206848],\n",
       " [0.9239853620529175, -0.24356165528297424, 1.5818185806274414],\n",
       " [3.2026851177215576, -0.4649634063243866, 1.101290225982666],\n",
       " [2.525400161743164, -0.19784456491470337, -0.16330373287200928],\n",
       " [0.04213160276412964, -0.09437581896781921, 0.8801637887954712]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = model.encoder(inputs)\n",
    "encoder_list = encoder.tolist()\n",
    "encoder_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "33d14c99-4741-42ef-bf62-4a9e15cb0d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9262295961380005, -0.4425962567329407, 1.7497654557228088]\n",
      "[0.10999786853790283, -0.34752899408340454, 0.25727951526641846]\n",
      "[3.754844546318054, -0.4754798114299774, -0.645664632320404]\n"
     ]
    }
   ],
   "source": [
    "def calc(first, second, third):\n",
    "    a = [0] * 3\n",
    "    a[0] = encoder_list[first][0] - encoder_list[second][0] + encoder_list[third][0]\n",
    "    a[1] = encoder_list[first][1] - encoder_list[second][1] + encoder_list[third][1]\n",
    "    a[2] = encoder_list[first][2] - encoder_list[second][2] + encoder_list[third][2]\n",
    "    print(a)\n",
    "\n",
    "calc(0, 4, 7) # 2\n",
    "calc(0, 1, 7) # 6\n",
    "calc(8, 7, 4) # 9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
